{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sound-population",
   "metadata": {},
   "source": [
    "# Cart-Pole with Policy Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "silent-experience",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from itertools import count\n",
    "from logger import Logger\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "circular-relief",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7facf27bee80>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "atmospheric-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ HYPERPARAMETERS ##############\n",
    "FRAMES = 2\n",
    "RESIZE_PIXELS = 60\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "LR = 0.00001\n",
    "GAMMA = 0.99\n",
    "END_SCORE = 1000\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "vocational-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ ENVIRONMENT ##############\n",
    "\n",
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.env = gym.make(\"CartPole-v0\").unwrapped\n",
    "        self.env.reset()\n",
    "        \n",
    "        screen = self.env.render(mode='rgb_array').transpose((2,0,1))\n",
    "        _, self.screen_height, self.screen_width = screen.shape\n",
    "        \n",
    "        self.resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(RESIZE_PIXELS, interpolation=Image.CUBIC),\n",
    "                    T.Grayscale(),\n",
    "                    T.ToTensor()])\n",
    "        \n",
    "        world_width = self.env.x_threshold * 2\n",
    "        self.scale = self.screen_width / world_width\n",
    "        \n",
    "    def get_cart_location(self):\n",
    "        return int(self.env.state[0] * self.scale + self.screen_width / 2.0)\n",
    "        \n",
    "    def get_screen(self):\n",
    "        screen = self.env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "        \n",
    "        screen = screen[:, int(self.screen_height*0.4):int(self.screen_height * 0.8)]\n",
    "        view_width = int(self.screen_width * 0.6)\n",
    "        cart_location = self.get_cart_location()\n",
    "        if cart_location < view_width // 2:\n",
    "            slice_range = slice(view_width)\n",
    "        elif cart_location > (self.screen_width - view_width // 2):\n",
    "            slice_range = slice(-view_width, None)\n",
    "        else:\n",
    "            slice_range = slice(cart_location - view_width // 2,\n",
    "                                cart_location + view_width // 2)\n",
    "        screen = screen[:, :, slice_range]\n",
    "        screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "        screen = torch.from_numpy(screen)\n",
    "        return self.resize(screen).unsqueeze(0)\n",
    "    \n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "        \n",
    "    def step(self, action):\n",
    "        return self.env.step(action)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "exciting-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NETWORK ##############\n",
    "'''\n",
    "For policy gradient, the network should input the raw pixels, and output the probabilities of choosing either 0 or 1\n",
    "'''\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self,h=60,w=135,device='cuda:0'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        input_channel = 2\n",
    "        hidden_channel = 64\n",
    "        hidden_channel2 = 32\n",
    "        kernel_size = 5\n",
    "        stride = 2\n",
    "        \n",
    "        self.base = nn.Sequential(\n",
    "            nn.Conv2d(input_channel, hidden_channel, kernel_size = kernel_size, stride = stride),\n",
    "            nn.BatchNorm2d(hidden_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channel, hidden_channel, kernel_size = kernel_size, stride = stride),\n",
    "            nn.BatchNorm2d(hidden_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channel, hidden_channel2, kernel_size = kernel_size, stride = stride),\n",
    "            nn.BatchNorm2d(hidden_channel2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        def conv2d_size_out(size, kernel_size = kernel_size, stride = stride):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        \n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * hidden_channel2\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(linear_input_size, 24),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.to(self.device)\n",
    "        x = self.base(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.head(x)\n",
    "        return F.softmax(x,dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "progressive-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "complicated-possession",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.step(0)\n",
    "plt.figure()\n",
    "plt.imshow(env.get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy().squeeze(), cmap='gray')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "authorized-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_shape = env.get_screen().shape\n",
    "policy_net = Network(h = screen_shape[2], w = screen_shape[3], device = device).to(device)\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "compound-cinema",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5225, 0.4775]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_screen = env.get_screen().to(device)\n",
    "c_screen = env.get_screen().to(device)\n",
    "\n",
    "x = torch.cat((p_screen, c_screen),dim=1)\n",
    "\n",
    "policy_net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "operational-champagne",
   "metadata": {},
   "outputs": [],
   "source": [
    "HISTORY = []\n",
    "\n",
    "def discount_rewards(r):\n",
    "    discounted_r = torch.zeros(r.size())\n",
    "    running_add = 0\n",
    "    for t in reversed(range(len(r))):\n",
    "        running_add = running_add * GAMMA + r[t]\n",
    "        discounted_r[t] = running_add\n",
    "\n",
    "    return discounted_r\n",
    "\n",
    "def run_episode(net, episode, env, logger = None):\n",
    "    net.eval()\n",
    "    state = env.reset()\n",
    "    prev_screen = env.get_screen().to(device)\n",
    "    \n",
    "    reward_sum = 0\n",
    "    xs = torch.FloatTensor([]).to(device)\n",
    "    ys = torch.FloatTensor([]).to(device)\n",
    "    rewards = torch.FloatTensor([]).to(device)\n",
    "    steps = 0\n",
    "\n",
    "    for t in count():\n",
    "        screen = env.get_screen().to(device)\n",
    "        \n",
    "        x = torch.cat((prev_screen, screen), dim=1)\n",
    "        \n",
    "        action_prob = net(x)\n",
    "\n",
    "        action = 0 if random.random() < action_prob[0][0] else 1\n",
    "\n",
    "        y = torch.FloatTensor([[1, 0]] if action == 0 else [[0, 1]]).to(device)\n",
    "        \n",
    "        xs = torch.cat([xs, x])\n",
    "        ys = torch.cat([ys, y])\n",
    "        \n",
    "        prev_screen = screen\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # Reward modification for better stability\n",
    "        x, x_dot, theta, theta_dot = state\n",
    "        r1 = (env.env.x_threshold - abs(x)) / env.env.x_threshold - 0.8\n",
    "        r2 = (env.env.theta_threshold_radians - abs(theta)) / env.env.theta_threshold_radians - 0.5\n",
    "        reward = r1 + r2\n",
    "        #reward = torch.tensor([reward], device=device)\n",
    "        if t >= END_SCORE-1:\n",
    "            reward = reward + 20\n",
    "            done = 1\n",
    "        else: \n",
    "            if done:\n",
    "                reward = reward - 20 \n",
    "        \n",
    "        rewards = torch.cat([rewards, torch.FloatTensor([[reward]]).to(device)])\n",
    "        reward_sum += reward\n",
    "        steps += 1\n",
    "    \n",
    "\n",
    "        if done or steps >= 1000:\n",
    "            adv = discount_rewards(rewards)\n",
    "            #adv = adv/(adv.std())\n",
    "            #adv = (adv - adv.mean())\n",
    "            #adv = (adv - adv.mean())/(adv.std() + 1e-7)\n",
    "            #print(adv)\n",
    "            loss = learn(xs, ys, adv, net)\n",
    "            #HISTORY.append(reward_sum)\n",
    "            print(\"[Episode {:>5}]  steps: {:>5} loss: {:>5}\".format(episode, steps, loss))\n",
    "            #if sum(HISTORY[-100:])/100 > 980:\n",
    "                #return True\n",
    "            #else:\n",
    "                #return False\n",
    "            if logger != None:\n",
    "                log.log_reward(reward=steps,episode=episode)\n",
    "            return False\n",
    "\n",
    "def learn(x, y, adv, model):\n",
    "    model.train()\n",
    "    # Loss function, ∑ Ai*logp(yi∣xi), but we need fake lable Y due to autodiff\n",
    "    action_pred = model(x)\n",
    "    y = Variable(y, requires_grad=True)\n",
    "    adv = Variable(adv).to(device)\n",
    "    # print(action_pred)\n",
    "    log_lik = -y * torch.log(action_pred)\n",
    "    # print(y)\n",
    "    log_lik_adv = log_lik * adv\n",
    "    # print(torch.sum(log_lik_adv, 1))\n",
    "    loss = torch.sum(log_lik_adv, 1).mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "executive-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"PG hidden=64 lr={LR} max_steps=1000 Adam\"\n",
    "log = Logger(model_name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-revision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode   201]  steps:    55 loss: -4.024871826171875\n",
      "[Episode   202]  steps:    20 loss: -11.869795799255371\n",
      "[Episode   203]  steps:   111 loss: -3.0275676250457764\n",
      "[Episode   204]  steps:    22 loss: -12.69566535949707\n",
      "[Episode   205]  steps:    37 loss: -11.543976783752441\n",
      "[Episode   206]  steps:    29 loss: -10.005578994750977\n",
      "[Episode   207]  steps:    21 loss: -12.927447319030762\n",
      "[Episode   208]  steps:    30 loss: -9.152851104736328\n",
      "[Episode   209]  steps:    26 loss: -11.9569730758667\n",
      "[Episode   210]  steps:   134 loss: -4.264444351196289\n",
      "[Episode   211]  steps:    27 loss: -9.97315788269043\n",
      "[Episode   212]  steps:    50 loss: -6.584788799285889\n",
      "[Episode   213]  steps:    40 loss: -9.861287117004395\n",
      "[Episode   214]  steps:    19 loss: -11.70457935333252\n",
      "[Episode   215]  steps:    10 loss: -16.454923629760742\n",
      "[Episode   216]  steps:    12 loss: -11.771957397460938\n",
      "[Episode   217]  steps:    45 loss: -8.644630432128906\n",
      "[Episode   218]  steps:    36 loss: -8.825589179992676\n",
      "[Episode   219]  steps:    12 loss: -11.944892883300781\n",
      "[Episode   220]  steps:    23 loss: -11.963385581970215\n",
      "[Episode   221]  steps:    30 loss: -10.635242462158203\n",
      "[Episode   222]  steps:    42 loss: -5.633277416229248\n",
      "[Episode   223]  steps:    17 loss: -12.53472900390625\n",
      "[Episode   224]  steps:    17 loss: -12.357706069946289\n",
      "[Episode   225]  steps:    18 loss: -11.552886962890625\n",
      "[Episode   226]  steps:    22 loss: -10.387920379638672\n",
      "[Episode   227]  steps:    10 loss: -17.131582260131836\n",
      "[Episode   228]  steps:    29 loss: -8.610260963439941\n",
      "[Episode   229]  steps:    21 loss: -9.868976593017578\n",
      "[Episode   230]  steps:    15 loss: -13.611492156982422\n",
      "[Episode   231]  steps:    32 loss: -11.09868049621582\n",
      "[Episode   232]  steps:    23 loss: -8.424162864685059\n",
      "[Episode   233]  steps:    15 loss: -12.236355781555176\n",
      "[Episode   234]  steps:    33 loss: -9.34288215637207\n",
      "[Episode   235]  steps:    46 loss: -6.539218425750732\n",
      "[Episode   236]  steps:    11 loss: -14.562164306640625\n",
      "[Episode   237]  steps:    34 loss: -11.087221145629883\n",
      "[Episode   238]  steps:    38 loss: -7.5567498207092285\n",
      "[Episode   239]  steps:    42 loss: -10.72733211517334\n",
      "[Episode   240]  steps:    19 loss: -13.3010892868042\n",
      "[Episode   241]  steps:    45 loss: -6.280359268188477\n",
      "[Episode   242]  steps:    16 loss: -12.734947204589844\n",
      "[Episode   243]  steps:    44 loss: -7.568620204925537\n",
      "[Episode   244]  steps:    13 loss: -15.230783462524414\n",
      "[Episode   245]  steps:    31 loss: -11.447444915771484\n",
      "[Episode   246]  steps:    24 loss: -10.779123306274414\n",
      "[Episode   247]  steps:    60 loss: -6.519580841064453\n",
      "[Episode   248]  steps:    63 loss: -7.890527725219727\n",
      "[Episode   249]  steps:    35 loss: -8.846226692199707\n",
      "[Episode   250]  steps:    23 loss: -8.588481903076172\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for episode in range(100000):\n",
    "    complete = run_episode(policy_net, episode, env,log)\n",
    "\n",
    "    if complete:\n",
    "        print('complete...!')\n",
    "        break\n",
    "    \n",
    "    if episode % 50 == 0:\n",
    "        clear_output(wait=True)\n",
    "        time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-album",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
