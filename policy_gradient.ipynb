{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "suspected-shopper",
   "metadata": {},
   "source": [
    "# Cart-Pole with Policy Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "african-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from itertools import count\n",
    "from logger import Logger\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "passing-playlist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7f0a2c736b38>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "silver-vertex",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ HYPERPARAMETERS ##############\n",
    "FRAMES = 2\n",
    "RESIZE_PIXELS = 60\n",
    "\n",
    "device = 'cuda:0'\n",
    "\n",
    "LR = 1e-5\n",
    "GAMMA = 0.99\n",
    "END_SCORE = 1000\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "occasional-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "############ ENVIRONMENT ##############\n",
    "\n",
    "class Environment:\n",
    "    def __init__(self):\n",
    "        self.env = gym.make(\"CartPole-v0\").unwrapped\n",
    "        self.env.reset()\n",
    "        \n",
    "        screen = self.env.render(mode='rgb_array').transpose((2,0,1))\n",
    "        _, self.screen_height, self.screen_width = screen.shape\n",
    "        \n",
    "        self.resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(RESIZE_PIXELS, interpolation=Image.CUBIC),\n",
    "                    T.Grayscale(),\n",
    "                    T.ToTensor()])\n",
    "        \n",
    "        world_width = self.env.x_threshold * 2\n",
    "        self.scale = self.screen_width / world_width\n",
    "        \n",
    "    def get_cart_location(self):\n",
    "        return int(self.env.state[0] * self.scale + self.screen_width / 2.0)\n",
    "        \n",
    "    def get_screen(self):\n",
    "        screen = self.env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "        \n",
    "        screen = screen[:, int(self.screen_height*0.4):int(self.screen_height * 0.8)]\n",
    "        view_width = int(self.screen_width * 0.6)\n",
    "        cart_location = self.get_cart_location()\n",
    "        if cart_location < view_width // 2:\n",
    "            slice_range = slice(view_width)\n",
    "        elif cart_location > (self.screen_width - view_width // 2):\n",
    "            slice_range = slice(-view_width, None)\n",
    "        else:\n",
    "            slice_range = slice(cart_location - view_width // 2,\n",
    "                                cart_location + view_width // 2)\n",
    "        screen = screen[:, :, slice_range]\n",
    "        screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "        screen = torch.from_numpy(screen)\n",
    "        return self.resize(screen).unsqueeze(0)\n",
    "    \n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "        \n",
    "    def step(self, action):\n",
    "        return self.env.step(action)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "experimental-adjustment",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NETWORK ##############\n",
    "'''\n",
    "For policy gradient, the network should input the raw pixels, and output the probabilities of choosing either 0 or 1\n",
    "'''\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self,h=60,w=135,device='cuda:0'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        input_channel = 2\n",
    "        hidden_channel = 64\n",
    "        hidden_channel2 = 32\n",
    "        kernel_size = 5\n",
    "        stride = 2\n",
    "        \n",
    "        self.base = nn.Sequential(\n",
    "            nn.Conv2d(input_channel, hidden_channel, kernel_size = kernel_size, stride = stride),\n",
    "            nn.BatchNorm2d(hidden_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channel, hidden_channel, kernel_size = kernel_size, stride = stride),\n",
    "            nn.BatchNorm2d(hidden_channel),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channel, hidden_channel2, kernel_size = kernel_size, stride = stride),\n",
    "            nn.BatchNorm2d(hidden_channel2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        def conv2d_size_out(size, kernel_size = kernel_size, stride = stride):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        \n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * hidden_channel2\n",
    "        \n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(linear_input_size, 24),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x = x.to(self.device)\n",
    "        x = self.base(x)\n",
    "        x = x.flatten(1)\n",
    "        x = self.head(x)\n",
    "        return F.softmax(x,dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "roman-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "smaller-demonstration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.step(0)\n",
    "plt.figure()\n",
    "plt.imshow(env.get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy().squeeze(), cmap='gray')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "juvenile-smart",
   "metadata": {},
   "outputs": [],
   "source": [
    "screen_shape = env.get_screen().shape\n",
    "policy_net = Network(h = screen_shape[2], w = screen_shape[3], device = device).to(device)\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "blond-amsterdam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4783, 0.5217]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_screen = env.get_screen().to(device)\n",
    "c_screen = env.get_screen().to(device)\n",
    "\n",
    "x = torch.cat((p_screen, c_screen),dim=1)\n",
    "\n",
    "policy_net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "billion-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "HISTORY = []\n",
    "\n",
    "def discount_rewards(r):\n",
    "    discounted_r = torch.zeros(r.size())\n",
    "    running_add = 0\n",
    "    for t in reversed(range(len(r))):\n",
    "        running_add = running_add * GAMMA + r[t]\n",
    "        discounted_r[t] = running_add\n",
    "\n",
    "    return discounted_r\n",
    "\n",
    "def run_episode(net, episode, env, logger = None):\n",
    "    net.eval()\n",
    "    state = env.reset()\n",
    "    prev_screen = env.get_screen().to(device)\n",
    "    \n",
    "    reward_sum = 0\n",
    "    xs = torch.FloatTensor([]).to(device)\n",
    "    ys = torch.FloatTensor([]).to(device)\n",
    "    rewards = torch.FloatTensor([]).to(device)\n",
    "    steps = 0\n",
    "\n",
    "    for t in count():\n",
    "        screen = env.get_screen().to(device)\n",
    "        \n",
    "        x = torch.cat((prev_screen, screen), dim=1)\n",
    "        \n",
    "        action_prob = net(x)\n",
    "\n",
    "        action = 0 if random.random() < action_prob[0][0] else 1\n",
    "\n",
    "        y = torch.FloatTensor([[1, 0]] if action == 0 else [[0, 1]]).to(device)\n",
    "        \n",
    "        xs = torch.cat([xs, x])\n",
    "        ys = torch.cat([ys, y])\n",
    "        \n",
    "        prev_screen = screen\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        \n",
    "#         # Reward modification for better stability\n",
    "#         x, x_dot, theta, theta_dot = state\n",
    "#         r1 = (env.env.x_threshold - abs(x)) / env.env.x_threshold - 0.8\n",
    "#         r2 = (env.env.theta_threshold_radians - abs(theta)) / env.env.theta_threshold_radians - 0.5\n",
    "#         reward = r1 + r2\n",
    "#         #reward = torch.tensor([reward], device=device)\n",
    "#         if t >= END_SCORE-1:\n",
    "#             reward = reward + 20\n",
    "#             done = 1\n",
    "#         else: \n",
    "#             if done:\n",
    "#                 reward = reward - 20 \n",
    "        \n",
    "        rewards = torch.cat([rewards, torch.FloatTensor([[reward]]).to(device)])\n",
    "        reward_sum += reward\n",
    "        steps += 1\n",
    "    \n",
    "\n",
    "        if done or steps >= 1000:\n",
    "            adv = discount_rewards(rewards)\n",
    "            #adv = adv/(adv.std())\n",
    "            adv = (adv - adv.mean())\n",
    "            #adv = (adv - adv.mean())/(adv.std() + 1e-7)\n",
    "            #print(adv)\n",
    "            loss = learn(xs, ys, adv, net)\n",
    "            #HISTORY.append(reward_sum)\n",
    "            print(\"[Episode {:>5}]  steps: {:>5} loss: {:>5}\".format(episode, steps, loss))\n",
    "            #if sum(HISTORY[-100:])/100 > 980:\n",
    "                #return True\n",
    "            #else:\n",
    "                #return False\n",
    "            if logger != None:\n",
    "                log.log_reward(reward=steps,episode=episode)\n",
    "            return False\n",
    "\n",
    "def learn(x, y, adv, model):\n",
    "    model.train()\n",
    "    # Loss function, ∑ Ai*logp(yi∣xi), but we need fake lable Y due to autodiff\n",
    "    action_pred = model(x)\n",
    "    y = Variable(y, requires_grad=True)\n",
    "    adv = Variable(adv).to(device)\n",
    "    # print(action_pred)\n",
    "    log_lik = -y * torch.log(action_pred)\n",
    "    # print(y)\n",
    "    log_lik_adv = log_lik * adv\n",
    "    # print(torch.sum(log_lik_adv, 1))\n",
    "    loss = torch.sum(log_lik_adv, 1).mean()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "union-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"PG hidden=64 lr={LR} max_steps=1000 Adam\"\n",
    "log = Logger(model_name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "micro-coupon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Episode   501]  steps:    10 loss: 0.4102818965911865\n",
      "[Episode   502]  steps:     9 loss: 0.3250013589859009\n",
      "[Episode   503]  steps:     9 loss: 0.33786827325820923\n",
      "[Episode   504]  steps:     9 loss: 0.0017716222209855914\n",
      "[Episode   505]  steps:     9 loss: 0.07566113024950027\n",
      "[Episode   506]  steps:    13 loss: -0.48566263914108276\n",
      "[Episode   507]  steps:     9 loss: 0.04736640676856041\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-7072f4ea7482>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mcomplete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcomplete\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-86ecfdc44934>\u001b[0m in \u001b[0;36mrun_episode\u001b[0;34m(net, episode, env, logger)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_screen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0maction_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0maction_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-6a6dccf9bef2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m#x = x.to(self.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             self.weight, self.bias, bn_training, exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2056\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   2057\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2058\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2059\u001b[0m     )\n\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "for episode in range(100000):\n",
    "    complete = run_episode(policy_net, episode, env,log)\n",
    "\n",
    "    if complete:\n",
    "        print('complete...!')\n",
    "        break\n",
    "    \n",
    "    if episode % 50 == 0:\n",
    "        clear_output(wait=True)\n",
    "        torch.save(policy_net.state_dict(), f'models/{name}.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
